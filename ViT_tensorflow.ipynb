{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
    "image_size = 28  # We'll resize input images to this size\n",
    "patch_size = 7  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 12\n",
    "mlp_head_units = [\n",
    "    2048,\n",
    "    1024,\n",
    "]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Create data augmentation stage\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Normalization(),\n",
    "        keras.layers.Resizing(image_size, image_size),\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(factor=0.02),\n",
    "        keras.layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "class Patches(keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = tf.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        patches = tf.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,\n",
    "                self.patch_size * self.patch_size * channels,\n",
    "            ),\n",
    "        )\n",
    "        return patches\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n",
    "    \n",
    "\n",
    "class PatchEncoder(keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patches):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PatchEncoder, self).get_config()\n",
    "        config.update({\"num_patches\": self.num_patches, \"projection_dim\": self.projection.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 28 X 28\n",
      "Patch size: 7 X 7\n",
      "Patches per image: 16\n",
      "Elements per patch: 147\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT model for image classification\n",
    "def ViT():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head self-attention mechanism.\n",
    "        attention_output = keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = keras.layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = keras.layers.Flatten()(representation)\n",
    "    representation = keras.layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = keras.layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " data_augmentation (Sequential)  (None, 28, 28, 3)   7           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " patches_1 (Patches)            (None, 16, 147)      0           ['data_augmentation[0][0]']      \n",
      "                                                                                                  \n",
      " patch_encoder (PatchEncoder)   (None, 16, 64)       10496       ['patches_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 16, 64)      128         ['patch_encoder[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 16, 64)      66368       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 64)       0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 16, 64)      128         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16, 128)      8320        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16, 128)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16, 64)       8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16, 64)       0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 64)       0           ['dropout_1[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 16, 64)      128         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 16, 64)      66368       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 64)       0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 16, 64)      128         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16, 128)      8320        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 128)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16, 64)       8256        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 64)       0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 64)       0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 16, 64)      128         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 16, 64)      66368       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 64)       0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 16, 64)      128         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 16, 128)      8320        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 16, 128)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16, 64)       8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 16, 64)       0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 64)       0           ['dropout_5[0][0]',              \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 16, 64)      128         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 16, 64)      66368       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 64)       0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 16, 64)      128         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 16, 128)      8320        ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 16, 128)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16, 64)       8256        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16, 64)       0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 16, 64)       0           ['dropout_7[0][0]',              \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 16, 64)      128         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 16, 64)      66368       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 16, 64)       0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 16, 64)      128         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 16, 128)      8320        ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 16, 128)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 16, 64)       8256        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 16, 64)       0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 16, 64)       0           ['dropout_9[0][0]',              \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 16, 64)      128         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 16, 64)      66368       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 16, 64)       0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 16, 64)      128         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 16, 128)      8320        ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 16, 128)      0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 16, 64)       8256        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 16, 64)       0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 16, 64)       0           ['dropout_11[0][0]',             \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 16, 64)      128         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 16, 64)      66368       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 16, 64)       0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 16, 64)      128         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 16, 128)      8320        ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 16, 128)      0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 16, 64)       8256        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 16, 64)       0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 16, 64)       0           ['dropout_13[0][0]',             \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 16, 64)      128         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 16, 64)      66368       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 16, 64)       0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 16, 64)      128         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 16, 128)      8320        ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 16, 128)      0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 16, 64)       8256        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 16, 64)       0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 16, 64)       0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 16, 64)      128         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 16, 64)      66368       ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 16, 64)       0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 16, 64)      128         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 16, 128)      8320        ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 16, 128)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 16, 64)       8256        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 16, 64)       0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 16, 64)       0           ['dropout_17[0][0]',             \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 16, 64)      128         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 16, 64)      66368       ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 16, 64)       0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 16, 64)      128         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 16, 128)      8320        ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 16, 128)      0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 16, 64)       8256        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 16, 64)       0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 16, 64)       0           ['dropout_19[0][0]',             \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 16, 64)      128         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 16, 64)      66368       ['layer_normalization_20[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 16, 64)       0           ['multi_head_attention_10[0][0]',\n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 16, 64)      128         ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 16, 128)      8320        ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 16, 128)      0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 16, 64)       8256        ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 16, 64)       0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 16, 64)       0           ['dropout_21[0][0]',             \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 16, 64)      128         ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 16, 64)      66368       ['layer_normalization_22[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 16, 64)       0           ['multi_head_attention_11[0][0]',\n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 16, 64)      128         ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 16, 128)      8320        ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 16, 128)      0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 16, 64)       8256        ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 16, 64)       0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 16, 64)       0           ['dropout_23[0][0]',             \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 16, 64)      128         ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 1024)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 2048)         2099200     ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 2048)         0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 1024)         2098176     ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 1024)         0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 100)          102500      ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,308,907\n",
      "Trainable params: 5,308,900\n",
      "Non-trainable params: 7\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ViT()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to set memory growth: Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "#  Set memory growth BEFORE initializing any TensorFlow/Keras objects\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Failed to set memory growth: {e}\")\n",
    "\n",
    "#  Enable mixed precision for better performance (optional)\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "def run_experiment(model, device=\"/GPU:0\"):\n",
    "    # Ensure GPU usage is visible in logs\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    try:\n",
    "        with tf.device(device):  # Set computation device\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[\n",
    "                    keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "                    keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Create checkpoint directory if it doesn't exist\n",
    "            checkpoint_dir = \"checkpoints\"\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            checkpoint_filepath = os.path.join(checkpoint_dir, \"vit_tf_model\")\n",
    "\n",
    "            # Callbacks for checkpointing & early stopping\n",
    "            checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                monitor=\"val_accuracy\",\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,  # Save full model\n",
    "                mode=\"max\",\n",
    "                verbose=1,\n",
    "            )\n",
    "\n",
    "            early_stopping = keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_accuracy\",\n",
    "                patience=5,  # Stop training if no improvement for 5 epochs\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                x=x_train,\n",
    "                y=y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=num_epochs,\n",
    "                validation_split=0.1,\n",
    "                callbacks=[checkpoint_callback, early_stopping],\n",
    "            )\n",
    "\n",
    "            # Load best model\n",
    "            model.load_weights(checkpoint_filepath)\n",
    "\n",
    "            # Evaluate the model\n",
    "            _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "            print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "            print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "            return history\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable logging for device placement\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Check available GPUs\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Details:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "DEVICE = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "vit_classifier = ViT()\n",
    "history = run_experiment(vit_classifier, device=DEVICE)\n",
    "\n",
    "\n",
    "def plot_history(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(\"loss\")\n",
    "plot_history(\"top-5-accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
